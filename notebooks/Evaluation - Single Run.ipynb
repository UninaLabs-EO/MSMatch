{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#Basic Imports\n",
    "import os,sys\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from tqdm import tqdm,trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report,confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "import pandas\n",
    "\n",
    "from datasets.ssl_dataset import SSL_Dataset\n",
    "from datasets.data_utils import get_data_loader\n",
    "from utils import get_model_checkpoints\n",
    "from utils import net_builder\n",
    "\n",
    "def plot_examples(images,labels,encoding, prediction=None):\n",
    "    fig = plt.figure(figsize=(8, 5), dpi=150)\n",
    "    for idx,img in enumerate(images[:32]):\n",
    "        ax = fig.add_subplot(4, 8, idx+1, xticks=[], yticks=[])\n",
    "        if np.max(img) > 1.5:\n",
    "            img = img / 255\n",
    "        plt.imshow(img)\n",
    "        if prediction is not None:\n",
    "            label = \"GT: \" + encoding[labels[idx]] + \"\\n PR: \" + encoding[prediction[idx]]\n",
    "        else:\n",
    "            label = encoding[labels[idx]]    \n",
    "        plt.title(str(label),fontsize=5)\n",
    "        \n",
    "def plot_cmatrix(pred,labels,encoding):\n",
    "    fig = plt.figure(figsize=(8, 5), dpi=150)\n",
    "    cm = confusion_matrix(labels,pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=encoding)\n",
    "    disp.plot(xticks_rotation=\"vertical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./saved_models/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints, args = get_model_checkpoints(path)\n",
    "args = args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"batch_size\"] = 256\n",
    "args[\"data_dir\"] = \"./data/\"\n",
    "args[\"use_train_model\"] = False\n",
    "args[\"load_path\"] = checkpoints[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(args[\"load_path\"])\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "load_model = (checkpoint[\"train_model\"] if args[\"use_train_model\"] else checkpoint[\"eval_model\"])\n",
    "\n",
    "_net_builder = net_builder(args[\"net\"],None,{})\n",
    "\n",
    "net = _net_builder(num_classes=args[\"num_classes\"])\n",
    "net.load_state_dict(load_model)\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "net.eval()\n",
    "\n",
    "_eval_dset = SSL_Dataset(name=args[\"dataset\"], train=False, data_dir=args[\"data_dir\"])\n",
    "eval_dset = _eval_dset.get_dset()\n",
    "\n",
    "eval_loader = get_data_loader(eval_dset, args[\"batch_size\"], num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding = _eval_dset.label_encoding\n",
    "inv_transf = _eval_dset.inv_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(eval_dset.data,eval_dset.targets,label_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assemble a batch\n",
    "images, labels, preds = [],[],[]\n",
    "with torch.no_grad():\n",
    "    for image, target in tqdm(eval_loader):\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        logit = net(image)\n",
    "        for idx,img in enumerate(image):\n",
    "            images.append(inv_transf(img.transpose(0,2).cpu().numpy()).transpose(0,2).numpy())\n",
    "        preds.append(logit.cpu().max(1)[1])\n",
    "        labels.append(target)\n",
    "labels = torch.cat(labels).numpy()\n",
    "preds = torch.cat(preds).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(images[32:],labels,label_encoding,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_report = classification_report(labels, preds, target_names=label_encoding, output_dict=True)\n",
    "print(classification_report(labels, preds, target_names=label_encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cmatrix(preds,labels,label_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store results in a file\n",
    "import pandas as pd\n",
    "test_frame = pd.DataFrame(test_report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame.to_csv(FLAGS.ckpt + \"_test_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
