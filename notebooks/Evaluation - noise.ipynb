{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#Basic Imports\n",
    "import os,sys\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from tqdm import tqdm,trange\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "\n",
    "from datasets.ssl_dataset import SSL_Dataset\n",
    "from datasets.data_utils import get_data_loader\n",
    "from utils import get_model_checkpoints\n",
    "from utils import net_builder\n",
    "from utils import clean_results_df\n",
    "from utils import get_model_checkpoints\n",
    "\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) - Set noise parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_noise_dB_min = 0 #[dB], Noise power in dB\n",
    "P_noise_dB_max = 27 #[dB], Max Noise power in dB \n",
    "dP_noise_dB = 3 # [dB], Delta power in dB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) - Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to the runs to load\n",
    "csv_folder = \"/home/gabrielemeoni/project/SSLRS/test\"\n",
    "folder = \"/scratch/fixmatch_results/new_runs/nr_of_labels/eurosat_rgb/\"\n",
    "sort_criterion = \"numlabels\" # Accepted net, numlabels\n",
    "seed_wanted = 0 # Seed wanted (the others will be filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints, run_args = get_model_checkpoints(folder)\n",
    "if os.name == 'nt':\n",
    "       [print(_.split(\"\\\\\")[1]) for _ in checkpoints];\n",
    "else:\n",
    "       [print(_.split(\"/\")[1]) for _ in checkpoints];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) - Evaluate all test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for checkpoint, args in zip(checkpoints,run_args):\n",
    "    print(\"------------ RUNNING \", checkpoint, \" -----------------\")\n",
    "    print(args)\n",
    "    args[\"batch_size\"] = 256\n",
    "    args[\"data_dir\"] = \"./data/\"\n",
    "    args[\"use_train_model\"] = False\n",
    "    args[\"load_path\"] = checkpoint\n",
    "    \n",
    "    if args[\"seed\"] == seed_wanted:\n",
    "        checkpoint_path = os.path.join(args[\"load_path\"])\n",
    "        checkpoint = torch.load(checkpoint_path,map_location='cuda:0')\n",
    "        load_model = (checkpoint[\"train_model\"] if args[\"use_train_model\"] else checkpoint[\"eval_model\"])\n",
    "        _net_builder = net_builder(args[\"net\"],False,{})\n",
    "        _eval_dset = SSL_Dataset(name=args[\"dataset\"], train=False, data_dir=args[\"data_dir\"], seed=args[\"seed\"])\n",
    "        eval_dset = _eval_dset.get_dset()\n",
    "        inv_transf = _eval_dset.inv_transform\n",
    "        transf = _eval_dset.transform\n",
    "        net = _net_builder(num_classes=_eval_dset.num_classes, in_channels=_eval_dset.num_channels)\n",
    "        net.load_state_dict(load_model)\n",
    "        if torch.cuda.is_available():\n",
    "            net.cuda()\n",
    "        net.eval()\n",
    "                        \n",
    "        eval_loader = get_data_loader(eval_dset, args[\"batch\"], num_workers=1)\n",
    "        label_encoding = _eval_dset.label_encoding\n",
    "        dB_value_list = []\n",
    "        resuts_run = []\n",
    "        \n",
    "        for P_noise_dB in range(P_noise_dB_min, P_noise_dB_max, dP_noise_dB):\n",
    "            print(\"------------ PREDICTING TESTSET ----------------- - Noise value [dB]\", P_noise_dB)\n",
    "            \n",
    "            \n",
    "            images, labels, preds = [],[],[]\n",
    "            with torch.no_grad():\n",
    "                for image, target in tqdm(eval_loader):\n",
    "                    image_preprocessed=[]\n",
    "                    for idx,img in enumerate(image):\n",
    "                        img=255 * inv_transf(img.transpose(0,2).cpu().numpy())\n",
    "                        img_orig=img\n",
    "                        for n in range(img.shape[0]):\n",
    "                            img[n]=(0.75 + 0.5 * torch.rand(size=(1,))) * img[n]\n",
    "                        \n",
    "                        A_noise = (10**(P_noise_dB/20))\n",
    "                        noise=torch.randn(size=img.shape) * A_noise\n",
    "                        img+= noise\n",
    "                        \n",
    "                        image[idx] = transf(1/255*torch.clip(img, 0, 255).transpose(0,2).cpu().numpy())\n",
    "                            \n",
    "                    logit = net(image.cuda())\n",
    "                    preds.append(logit.cpu().max(1)[1])\n",
    "                    labels.append(target)\n",
    "            labels = torch.cat(labels).numpy()\n",
    "            preds = torch.cat(preds).numpy()\n",
    "            test_report = classification_report(labels, preds, target_names=label_encoding, output_dict=True)\n",
    "            test_report[\"params\"] = args\n",
    "            dB_value_list.append(\"P_noise_\"+str(P_noise_dB)+\"_dB\")\n",
    "            resuts_run.append(test_report)\n",
    "        results_noise_dict = dict(zip(dB_value_list, resuts_run))\n",
    "        results.append(results_noise_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) - Creating a PANDAS dataframe and export it to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = pd.DataFrame()\n",
    "pd.set_option('display.max_columns', None)\n",
    "for result in results:\n",
    "    df = pd.DataFrame()\n",
    "    for dB_value in dB_value_list:\n",
    "        if dB_value == 'P_noise_0_dB':\n",
    "            result_0_dB = result['P_noise_0_dB']\n",
    "            params = result_0_dB[\"params\"]\n",
    "            df_local = pd.DataFrame(result_0_dB)\n",
    "            df_local.drop(list(params.keys()),inplace=True)\n",
    "            accuracy_0_dB = df_local['accuracy']\n",
    "            df_local.drop([\"support\",\"recall\",\"precision\"],inplace=True)\n",
    "            df_local.drop('accuracy',axis=1 ,inplace=True)\n",
    "            \n",
    "            for key,val in params.items():\n",
    "                df_local[key] = val\n",
    "                \n",
    "            df_local = df_local.set_index(\"dataset\")\n",
    "            df_local.insert(len(df_local.columns), 'accuracy - [0dB]', accuracy_0_dB)\n",
    "            #df_local = df_local.rename(columns={'accuracy': 'accuracy - [0dB]'})\n",
    "            \n",
    "            df=df_local\n",
    "        else:\n",
    "            results_n_dB = result[dB_value]\n",
    "            df.insert(len(df.columns), 'accuracy - ['+dB_value.replace(\"P_noise_\",\"\").replace(\"_dB\",\"\")+\"dB]\", results_n_dB[\"accuracy\"])\n",
    "\n",
    "    big_df = big_df.append(df)\n",
    "\n",
    "\n",
    "small_df = clean_results_df(big_df, folder,sort_criterion)\n",
    "print(small_df)\n",
    "small_df.to_csv(csv_folder + \"_test_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) - Creating plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for numlabels in small_df[\"numlabels\"]:\n",
    "    acc_numlabels=small_df.loc[small_df[\"numlabels\"] == numlabels]\n",
    "    accuracy_values = []\n",
    "    for dB_value in dB_value_list:\n",
    "        accuracy_values.append(acc_numlabels['accuracy - ['+dB_value.replace(\"P_noise_\",\"\").replace(\"_dB\",\"\")+\"dB]\"] * 100)\n",
    "    \n",
    "    plt.plot(np.arange(P_noise_dB_min, P_noise_dB_max, dP_noise_dB), accuracy_values)\n",
    "    \n",
    "\n",
    "plt.legend(small_df[\"numlabels\"])\n",
    "plt.xlabel('noise power [dB]')\n",
    "plt.ylabel('Accuracy [%]') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
