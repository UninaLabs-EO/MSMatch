{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#Basic Imports\n",
    "import os,sys\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from tqdm import tqdm,trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas\n",
    "\n",
    "from datasets.ssl_dataset import SSL_Dataset\n",
    "from datasets.data_utils import get_data_loader\n",
    "from utils import get_model_checkpoints\n",
    "from utils import net_builder\n",
    "from utils import clean_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary visualization code\n",
    "# Original code from https://github.com/utkuozbulak/pytorch-cnn-visualizations\n",
    "# slightly modified it to fit our needs\n",
    "from external.visualizations.guided_backprop import GuidedBackprop\n",
    "from external.visualizations.misc_functions import convert_to_grayscale,get_positive_negative_saliency\n",
    "from external.visualizations.smooth_grad import generate_smooth_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to the runs to load\n",
    "folder = R\"D:\\Arbeit\\Results\\fixmatch_results\\F1 Class plot/eurosat_rgb/\" # Folder where the runs are located\n",
    "sort_criterion = \"numlabels\" # Accepted net, numlabels\n",
    "seed_wanted = 0 # Seed wanted (the others will be filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints, run_args = get_model_checkpoints(folder)\n",
    "if os.name == 'nt':\n",
    "       [print(_.split(\"\\\\\")[1]) for _ in checkpoints];\n",
    "else:\n",
    "       [print(_.split(\"/\")[1]) for _ in checkpoints];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency = {} #will contain saliency maps for all runs\n",
    "N = 3 # how many images should be looked at\n",
    "\n",
    "_eval_dset = SSL_Dataset(\"eurosat_rgb\", train=False,  data_dir=\"./data/\", seed=seed_wanted)\n",
    "eval_dset = _eval_dset.get_dset()\n",
    "\n",
    "#Iterate over runs\n",
    "for path, args in zip(checkpoints,run_args):\n",
    "    print(\"------------ RUNNING \", path, \" -----------------\")\n",
    "    print(args)\n",
    "    args[\"data_dir\"] = \"./data/\"\n",
    "    args[\"use_train_model\"] = False\n",
    "    args[\"load_path\"] = path\n",
    "    saliency[args[\"numlabels\"]] = []\n",
    "    \n",
    "    if args[\"seed\"] != seed_wanted:\n",
    "        continue\n",
    "    \n",
    "    # Load the model and dataset\n",
    "    checkpoint_path = os.path.join(args[\"load_path\"])\n",
    "    checkpoint = torch.load(checkpoint_path,map_location='cuda:0')\n",
    "    load_model = (checkpoint[\"train_model\"] if args[\"use_train_model\"] else checkpoint[\"eval_model\"])\n",
    "    _net_builder = net_builder(args[\"net\"],False,{})\n",
    "    \n",
    "    net = _net_builder(num_classes=_eval_dset.num_classes, in_channels=_eval_dset.num_channels)\n",
    "    net.load_state_dict(load_model)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    net.eval()\n",
    "\n",
    "    eval_loader = get_data_loader(eval_dset, 1, num_workers=1) #note batchsize is manually set to 1 here\n",
    "    label_encoding = _eval_dset.label_encoding\n",
    "    inv_transf = _eval_dset.inv_transform\n",
    "    \n",
    "    # Init saliency computation algorithm\n",
    "    cam = GuidedBackprop(net)\n",
    "    \n",
    "    idx = 0 #current image index\n",
    "    image_original = [] # to store original images\n",
    "    \n",
    "    \n",
    "    for image, target in tqdm(eval_loader):\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        image_original.append(inv_transf(image[0].transpose(0,2).cpu().numpy()).transpose(0,2).numpy())\n",
    "        idx = idx + 1\n",
    "\n",
    "        # Use smooth grad by sampling the gradients with some noise added to image to get a smoother output\n",
    "        param_n = 100 #nr of images to sample\n",
    "        param_sigma_multiplier = 2 #noise strength\n",
    "        result = generate_smooth_grad(cam,  # ^This parameter\n",
    "                                           image,\n",
    "                                           target,\n",
    "                                           param_n,\n",
    "                                           param_sigma_multiplier)\n",
    "\n",
    "        result = result[:,0:64,0:64] #some padding happens in the network, we discard\n",
    "        result = convert_to_grayscale(result)\n",
    "        result, _ = get_positive_negative_saliency(result) #we only use positive saliency maps\n",
    "        saliency[args[\"numlabels\"]].append(result[0])\n",
    "\n",
    "        if idx > N:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_examples(images,saliency,numlabels=[50,100,500,1000,2000,3000],indices=[2]):\n",
    "    \"\"\" Small function to plot the results\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 1.5*len(indices)), dpi=150)\n",
    "    offset = len(numlabels) + 1\n",
    "    images = np.asarray(images)\n",
    "    for plot_nr,idx in enumerate(indices):\n",
    "        ax = fig.add_subplot(len(indices), offset, offset*plot_nr+1, xticks=[], yticks=[])\n",
    "        img = images[idx]\n",
    "        if np.max(img) > 1.5:\n",
    "            img = img / 255\n",
    "        plt.imshow(img)\n",
    "\n",
    "        for nl_idx,nl in enumerate(numlabels):\n",
    "            ax = fig.add_subplot(len(indices), offset, offset*plot_nr+2+nl_idx, xticks=[], yticks=[])\n",
    "            sal = np.flipud(saliency[nl][idx])\n",
    "            plt.contourf(sal,cmap=\"gnuplot2\")\n",
    "            \n",
    "indices_to_plot = np.arange(0,3)\n",
    "plot_examples(image_original,saliency,indices=indices_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
